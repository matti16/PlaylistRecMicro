{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <hr style=\"clear: both\" />\n",
    "\n",
    "# Running Spark in YARN-client mode\n",
    "\n",
    "This notebook demonstrates how to set up a SparkContext that uses SURFsara's Hadoop cluster: [YARN resourcemanager](http://head05.hathi.surfsara.nl:8088/cluster) (note you will need to be authenticated via kerberos on your machine to visit the resourcemanager link) for executors.\n",
    "\n",
    "First initialize kerberos via a Jupyter terminal. \n",
    "In the terminal execute: <BR>\n",
    "<i>kinit -k -t data/robertop.keytab robertop@CUA.SURFSARA.NL</i><BR>\n",
    "Print your credentials:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticket cache: FILE:/tmp/krb5cc_1001\r\n",
      "Default principal: robertop@CUA.SURFSARA.NL\r\n",
      "\r\n",
      "Valid starting       Expires              Service principal\r\n",
      "04/12/2016 13:42:29  04/13/2016 13:42:29  krbtgt/CUA.SURFSARA.NL@CUA.SURFSARA.NL\r\n",
      "\trenew until 04/12/2016 13:42:29\r\n"
     ]
    }
   ],
   "source": [
    "! klist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.context.SparkContext object at 0x7f4a2710e550>\n"
     ]
    }
   ],
   "source": [
    "print sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <hr style=\"clear: both\" />\n",
    "\n",
    "# Now you can run your code\n",
    "\n",
    "Pick a clustering algorithm (name of the file that provides a classify(x,y [,threshold]) function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "execfile('../spark-scripts/conventions.py')\n",
    "execfile('../spark-scripts/splitCluster2.py')\n",
    "#execfile('../spark-scripts/utils.py')\n",
    "execfile('../spark-scripts/eval.py')\n",
    "execfile('../spark-scripts/implicitPlaylistAlgoFunctions.py')\n",
    "execfile('../spark-scripts/implicitPlaylistAlgoMain.py')\n",
    "\n",
    "CLUSTER_ALGO = 'jaccardBase'\n",
    "\n",
    "execfile('../spark-scripts/' + CLUSTER_ALGO + '.py')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the conf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import copy\n",
    "\n",
    "BASE_PATH = \"/mnt/space/mattia\"\n",
    "\n",
    "conf = {}\n",
    "\n",
    "conf['split'] = {}\n",
    "conf['split']['reclistSize'] = 100\n",
    "conf['split']['callParams'] = {}\n",
    "conf['split']['excludeAlreadyListenedTest'] = True\n",
    "conf['split']['name'] = 'SenzaRipetizioni_1'\n",
    "conf['split']['split'] = conf['split']['name']\n",
    "conf['split']['minEventsPerUser'] = 5\n",
    "conf['split']['inputData'] = BASE_PATH + '/' + CLUSTER_ALGO + '.split/SenzaRipetizioni_1'\n",
    "#conf['split']['inputData'] = 's3n://contentwise-research-poli/30musicdataset/newFormat/relations/sessions.idomaar'\n",
    "conf['split']['bucketName'] = BASE_PATH\n",
    "conf['split']['percUsTr'] = 0.05\n",
    "conf['split']['ts'] = int(0.75 * (1421745857 - 1390209860) + 1390209860) - 10000\n",
    "conf['split']['minEventPerSession'] = 5\n",
    "conf['split']['onlineTrainingLength'] = 5\n",
    "conf['split']['GTlength'] = 1\n",
    "conf['split']['minEventPerSessionTraining'] = 10\n",
    "conf['split']['minEventPerSessionTest'] = 11\n",
    "conf['split']['mode'] = 'session'\n",
    "conf['split']['forceSplitCreation'] = False\n",
    "conf['split'][\"prop\"] = {'reclistSize': conf['split']['reclistSize']}\n",
    "conf['split']['type'] = list\n",
    "conf['split']['out'] = BASE_PATH + '/' + CLUSTER_ALGO + '.split'\n",
    "conf['split']['location'] = '30Mdataset/relations/sessions'\n",
    "\n",
    "conf['evaluation'] = {}\n",
    "conf['evaluation']['metric'] = {}\n",
    "conf['evaluation']['metric']['type'] = 'recall'\n",
    "conf['evaluation']['metric']['prop'] = {}\n",
    "conf['evaluation']['metric']['prop']['N'] = [1,2,5,10,15,20,25,50,100]\n",
    "conf['evaluation']['name'] = 'recall@N'\n",
    "\n",
    "conf['general'] = {}\n",
    "conf['general']['clientname'] = CLUSTER_ALGO + '.split'\n",
    "conf['general']['bucketName'] = BASE_PATH\n",
    "conf['general']['tracksPath'] = '30Mdataset/entities/tracks.idomaar.gz'\n",
    "\n",
    "conf['algo'] = {}\n",
    "conf['algo']['name'] = CLUSTER_ALGO\n",
    "conf['algo']['props'] = {}\n",
    "# ***** EXAMPLE OF CONFIGURATION *****#\n",
    "conf['algo']['props'][\"sessionJaccardShrinkage\"] = 5\n",
    "conf['algo']['props'][\"clusterSimilarityThreshold\"] = 0.1\n",
    "conf['algo']['props'][\"expDecayFactor\"] = 0.7\n",
    "# ****** END EXAMPLE ****************#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <hr style=\"clear: both\" />\n",
    "# Pick the list of songs ad create clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'0',\n",
       "  [u'000003',\n",
       "   u'music',\n",
       "   u'instructor',\n",
       "   u'dj27s',\n",
       "   u'rock',\n",
       "   u'da',\n",
       "   u'house',\n",
       "   u'c382e28988c386e28988c38a01',\n",
       "   u'dj',\n",
       "   u'maxpulemet',\n",
       "   u'vs',\n",
       "   u'bomfunk',\n",
       "   u'mc27s',\n",
       "   u'electro',\n",
       "   u'breakdance',\n",
       "   u'party',\n",
       "   u'1',\n",
       "   u'5b20005d',\n",
       "   u'cd',\n",
       "   u'onec382e28988c386e28988c38a'],\n",
       "  u'000003 Music Instructor Dj%27s Rock Da House %C3%82%E2%89%88%C3%86%E2%89%88%C3%8A01 - Dj Max-Pulemet Vs. Bomfunk Mc%27s - Electro Breakdance party 1 %5B2000%5D = CD ONE%C3%82%E2%89%88%C3%86%E2%89%88%C3%8A'),\n",
       " (u'1',\n",
       "  [u'0001', u'd0a2d0b5d0bad181d182'],\n",
       "  u'00-01 %D0%A2%D0%B5%D0%BA%D1%81%D1%82'),\n",
       " (u'2', [u'0005', u'overkill', u'overkill'], u'0005. Overkill Overkill')]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import string\n",
    "\n",
    "def my_replace_punct(x):\n",
    "    ret = \"\"\n",
    "    for i in x:\n",
    "        if i == '+':\n",
    "            ret += ' '\n",
    "        else:\n",
    "            ret += i\n",
    "    return ret\n",
    "\n",
    "tracksRDD = sc.textFile(BASE_PATH + '/30Mdataset/entities/tracks.idomaar.gz')\n",
    "tracksRDD = tracksRDD.map(lambda x: x.split('\\t')).map(lambda x: (x[1], json.loads(x[3])['name'].split('/') ) )\n",
    "tracksRDD = tracksRDD.map(lambda x: (x[0], \" \".join( (x[1][0], x[1][2]) ) ))\n",
    "tracksRDD = tracksRDD.map(lambda x : (x[0], my_replace_punct(x[1])))\n",
    "tracksRDD = tracksRDD.map(lambda x: (x[0], tokenize_song(x[1]), x[1]))\n",
    "\n",
    "\n",
    "sampleRDD = tracksRDD.take(50000)\n",
    "sampleRDD = sc.parallelize(sampleRDD)\n",
    "\n",
    "tracksIdsRDD = sampleRDD.map(lambda x: (x[0], [x[0]]))\n",
    "\n",
    "sampleRDD.take(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <hr style=\"clear: both\" />\n",
    "\n",
    "Reduce the quantity of data by building RDD {word -> songs}.\n",
    "For each word keep only couples of songs that match.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'and',\n",
       "  (((u'3081', u'112 Peaches And Cream'),\n",
       "    (u'2997', u'112 112 - Peaches and Cream')),\n",
       "   ((u'2859', u'10 Years ... And All The Other Colors'),\n",
       "    (u'2858', u'10 Years ...And All the Other Colors')),\n",
       "   ((u'43005',\n",
       "     u'69 Jazzfunkclassics - Ladies and gentlemen 69 Jazzfunkclassics - Ladies and gentlemen'),\n",
       "    (u'43004', u'69 Jazzfunkclassics Ladies and Gentlemen')),\n",
       "   ((u'19408', u'%3F and the Mysterians Can%27t Get Enough Of You, Baby'),\n",
       "    (u'19407', u'%3F and the Mysterians Can%27t Get Enough of You Baby')),\n",
       "   ((u'38964', u'%5Bunknown%5D Shut Up And Drive - Rihanna'),\n",
       "    (u'38420', u'%5Bunknown%5D Rihanna - Shut Up And Drive')),\n",
       "   ((u'47512',\n",
       "     u'9GOATS BLACK OUT Melancholy and the loneliness -%22%E6%86%82%E9%AC%B1%E3%81%A8%E5%AD%A4%E7%8B%AC%22 re-mix-'),\n",
       "    (u'47511',\n",
       "     u'9GOATS BLACK OUT Melancholy and the loneliness- %22%E6%86%82%E9%AC%B1%E3%81%A8%E5%AD%A4%E7%8B%AC%22 re-mix -')),\n",
       "   ((u'39817', u'%5Bunknown%5D The 12 Days of Christmas - Kunt and the Gang!'),\n",
       "    (u'35472', u'%5Bunknown%5D Kunt and the Gang - The 12 Days of Christmas')),\n",
       "   ((u'12792', u'2Pac (Feat. Dr. Dre And Roger Troutman) California Love'),\n",
       "    (u'12641', u'2Pac California Love (Feat. Dr. Dre and Roger Troutman)')),\n",
       "   ((u'44921', u'801 Law and Order (Live)'),\n",
       "    (u'44920', u'801 Law and Order - Live')),\n",
       "   ((u'14872',\n",
       "     u'30 Seconds to Mars Kings And Queens - Innerpartysystem Remix Main'),\n",
       "    (u'14871',\n",
       "     u'30 Seconds to Mars Kings and Queens (Innerpartysystem Remix Main)')),\n",
       "   ((u'8285', u'22-20s Shake, Shiver, And Moan'),\n",
       "    (u'8284', u'22-20s Shake, Shiver and Moan')),\n",
       "   ((u'48995', u'Aaliyah Back And  Forth'),\n",
       "    (u'48994', u'Aaliyah Back and Forth')),\n",
       "   ((u'28239', u'%5Bunknown%5D 1846 Suppe Poet And Peasant - Overture'),\n",
       "    (u'28238', u'%5Bunknown%5D 1846 Suppe - Poet and Peasant - Overture')),\n",
       "   ((u'13449', u'2Pac To Live And Die In L.A. feat. Val Young'),\n",
       "    (u'13448', u'2Pac to live and die in l.a. (feat. Val Young)')),\n",
       "   ((u'26049',\n",
       "     u'%5BThe%5D Slowest Runner %5Bin all the world%5D As the sea swells she bleats and moans like a goat in heat.'),\n",
       "    (u'26048',\n",
       "     u'%5BThe%5D Slowest Runner %5Bin all the world%5D As the sea swells she bleats and moans like a goat in heat')),\n",
       "   ((u'14881', u'30 Seconds to Mars Kings and Queens (unplugged)'),\n",
       "    (u'14880', u'30 Seconds to Mars Kings and Queens - unplugged')),\n",
       "   ((u'33648', u'%5Bunknown%5D florence and the machine heavy in your arms'),\n",
       "    (u'33647',\n",
       "     u'%5Bunknown%5D florence and the machine - heavy in your arms')))),\n",
       " (u'real',\n",
       "  (((u'49518', u'A$AP Ferg Real Thing ft. SZA'),\n",
       "    (u'49517', u'A$AP Ferg Real Thing (ft. SZA)')),\n",
       "   ((u'49516', u'A$AP Ferg Real Thing Feat. SZA'),\n",
       "    (u'49515', u'A$AP Ferg Real Thing (feat. SZA)')))),\n",
       " (u'aoki',\n",
       "  (((u'14311', u'2 Unlimited Get Ready (Steve Aoki Extended)'),\n",
       "    (u'14310', u'2 Unlimited Get Ready - Steve Aoki Extended')),\n",
       "   ((u'14309', u'2 Unlimited Get Ready (Steve Aoki Edit)'),\n",
       "    (u'14308', u'2 Unlimited Get Ready - Steve Aoki Edit'))))]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build an RDD with ('word' -> (id, name))\n",
    "wordsRDD = sampleRDD.flatMap(lambda x: [(i, (x[0], x[2])) for i in x[1]] )\n",
    "wordsRDD.take(3)\n",
    "\n",
    "#Group by 'word' and keep only the ones with more then 1 song\n",
    "wordsRDD = wordsRDD.groupByKey().mapValues(list).filter(lambda x: len(x[1]) > 1)\n",
    "\n",
    "#Compute a cartesian product for each list of songs with a common word\n",
    "def filtered_cartesian(x):\n",
    "    equal_couples = set()\n",
    "    for i in range(len(x[1])):\n",
    "        a = x[1][i]\n",
    "        id_a = x[1][i][0]\n",
    "        name_a = x[1][i][1]\n",
    "        \n",
    "        for j in range(i):\n",
    "            b = x[1][j]\n",
    "            id_b = x[1][j][0]\n",
    "            name_b = x[1][j][1]\n",
    "            if id_a != id_b:\n",
    "                if classify(name_a, name_b):\n",
    "                    equal_couples.add((a,b))\n",
    "                    \n",
    "    return (x[0], tuple(equal_couples))\n",
    "\n",
    "coupleRDD = wordsRDD.map(filtered_cartesian).filter(lambda x: len(x[1]) > 1)\n",
    "coupleRDD.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <hr style=\"clear: both\" />\n",
    "Flip the dataset and map each song to the couples it belongs to. \n",
    "Group by key and for each song you have a cluster!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Flatmap the list of couples\n",
    "flattedCoupleRDD = coupleRDD.flatMap(lambda x: [i for i in x[1]])\n",
    "#For each couple, for each song, yield song->couple\n",
    "flattedCoupleRDD = flattedCoupleRDD.flatMap(lambda x: ((i[0], (x[0], x[1]) )for i in x) )\n",
    "\n",
    "#Group by key (song). Each song has now one cluster\n",
    "def merge_couples(x, y):\n",
    "    return list(set(x) | set(y))\n",
    "\n",
    "songClusterRDD = flattedCoupleRDD.reduceByKey(merge_couples)\n",
    "songClusterRDD.take(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <hr style=\"clear: both\" />\n",
    "Complete the clusters with all the other songs. \n",
    "Then we need to map cluster to songs to have new IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'3610', [u'3610', u'3611']),\n",
       " (u'151', [u'151']),\n",
       " (u'605', [u'605']),\n",
       " (u'3922', [u'3922']),\n",
       " (u'3948', [u'3948']),\n",
       " (u'3773', [u'3773']),\n",
       " (u'4260', [u'4260']),\n",
       " (u'2617', [u'2617']),\n",
       " (u'740', [u'740']),\n",
       " (u'1304', [u'1304']),\n",
       " (u'2594', [u'2594']),\n",
       " (u'1227', [u'1227']),\n",
       " (u'883', [u'883']),\n",
       " (u'2778', [u'2778']),\n",
       " (u'1142', [u'1142']),\n",
       " (u'1087', [u'1087']),\n",
       " (u'3827', [u'3827']),\n",
       " (u'3759', [u'3759']),\n",
       " (u'2734', [u'2734']),\n",
       " (u'4303', [u'4303']),\n",
       " (u'1788', [u'1788']),\n",
       " (u'1164', [u'1164']),\n",
       " (u'1322', [u'1322']),\n",
       " (u'4365', [u'4365']),\n",
       " (u'623', [u'623']),\n",
       " (u'4189', [u'4189']),\n",
       " (u'1128', [u'1128']),\n",
       " (u'4329', [u'4329']),\n",
       " (u'2712', [u'2712']),\n",
       " (u'2903', [u'2903']),\n",
       " (u'3593', [u'3593']),\n",
       " (u'1348', [u'1348']),\n",
       " (u'3904', [u'3904']),\n",
       " (u'2860', [u'2860']),\n",
       " (u'3715', [u'3715']),\n",
       " (u'4080', [u'4080']),\n",
       " (u'216', [u'216']),\n",
       " (u'591', [u'591']),\n",
       " (u'2477', [u'2477']),\n",
       " (u'2965', [u'2965']),\n",
       " (u'458', [u'458']),\n",
       " (u'2929', [u'2929']),\n",
       " (u'3905', [u'3905']),\n",
       " (u'150', [u'150']),\n",
       " (u'3714', [u'3714']),\n",
       " (u'604', [u'604']),\n",
       " (u'2779', [u'2779']),\n",
       " (u'4081', [u'4081']),\n",
       " (u'2964', [u'2964']),\n",
       " (u'217', [u'217']),\n",
       " (u'2476', [u'2476']),\n",
       " (u'2928', [u'2928']),\n",
       " (u'3949', [u'3949']),\n",
       " (u'1165', [u'1165']),\n",
       " (u'4261', [u'4261']),\n",
       " (u'3923', [u'3923']),\n",
       " (u'3772', [u'3772']),\n",
       " (u'2616', [u'2616']),\n",
       " (u'4364', [u'4364']),\n",
       " (u'741', [u'741']),\n",
       " (u'1305', [u'1305']),\n",
       " (u'1226', [u'1226']),\n",
       " (u'2595', [u'2595']),\n",
       " (u'1086', [u'1086']),\n",
       " (u'882', [u'882']),\n",
       " (u'1143', [u'1143']),\n",
       " (u'3826', [u'3826']),\n",
       " (u'3611', [u'3610', u'3611']),\n",
       " (u'3758', [u'3758']),\n",
       " (u'2735', [u'2735']),\n",
       " (u'1789', [u'1789']),\n",
       " (u'622', [u'622']),\n",
       " (u'1323', [u'1323']),\n",
       " (u'4302', [u'4302']),\n",
       " (u'4188', [u'4188']),\n",
       " (u'4328', [u'4328']),\n",
       " (u'590', [u'590']),\n",
       " (u'3592', [u'3592']),\n",
       " (u'1349', [u'1349']),\n",
       " (u'2713', [u'2713']),\n",
       " (u'2902', [u'2902']),\n",
       " (u'2861', [u'2861']),\n",
       " (u'1129', [u'1129']),\n",
       " (u'459', [u'459']),\n",
       " (u'4301', [u'4301']),\n",
       " (u'579', [u'579']),\n",
       " (u'4899', [u'4899']),\n",
       " (u'593', [u'593']),\n",
       " (u'3591', [u'3591']),\n",
       " (u'881', [u'881']),\n",
       " (u'2862', [u'2862']),\n",
       " (u'2659', [u'2659']),\n",
       " (u'2901', [u'2901']),\n",
       " (u'2299', [u'2299']),\n",
       " (u'1225', [u'1225']),\n",
       " (u'4367', [u'4367']),\n",
       " (u'3906', [u'3906']),\n",
       " (u'3717', [u'3717']),\n",
       " (u'2967', [u'2967']),\n",
       " (u'4082', [u'4082'])]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#In this way we obtain a complete RDD with song -> group of songs\n",
    "def reduce_to_biggest(x, y):\n",
    "    bigger = x if len(x) > len(y) else y\n",
    "    result = sorted(bigger)\n",
    "    return result\n",
    "           \n",
    "unionRDD = songClusterRDD.union(tracksIdsRDD).reduceByKey(reduce_to_biggest)\n",
    "unionRDD.take(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "clusterSongsRDD = unionRDD.map(lambda x: (x[1], x[0])).groupByKey().mapValues(list)\n",
    "clusterSongsRDD = clusterSongsRDD.zipWithIndex().map(lambda x: (x[1], x[0][1]))\n",
    "clusterSongsRDD.saveAsTextFile(BASE_PATH + '/clusters/' + CLUSTER_ALGO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "splitter(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os import path\n",
    "basePath = path.join(conf['general']['bucketName'], conf['general']['clientname'])\n",
    "splitPath = path.join(basePath, conf['split']['name'])\n",
    "\n",
    "clusterSimList = [0.1]\n",
    "sessionJaccardShrinkageList = [5]\n",
    "expDecayList = [0.7]\n",
    "\n",
    "for exclude in [True]:\n",
    "    conf['split']['excludeAlreadyListenedTest'] = str(exclude)\n",
    "    #conf['split']['name'] = 'giroCompletoTestMultipleConfs_exclude%s' % exclude\n",
    "    #splitter(conf)\n",
    "    train, test = loadDataset(conf)\n",
    "    train.cache()\n",
    "    test.cache()\n",
    "    \n",
    "    for sessionJaccardShrinkage in sessionJaccardShrinkageList:\n",
    "        conf['algo']['props'][\"sessionJaccardShrinkage\"] = sessionJaccardShrinkage\n",
    "        \n",
    "        for clusterSim in clusterSimList:\n",
    "            conf['algo']['props'][\"clusterSimilarityThreshold\"] = clusterSim\n",
    "            \n",
    "            playlists = extractImplicitPlaylists(train, conf).cache()\n",
    "            \n",
    "            for expDecay in expDecayList:\n",
    "                conf['algo']['props'][\"expDecayFactor\"] = expDecay\n",
    "                conf['algo']['name'] = CLUSTER_ALGO + '_ImplicitPlaylist_shk_%d_clustSim_%.3f_decay_%.3f' % \\\n",
    "                    (sessionJaccardShrinkage, clusterSim, expDecay )\n",
    "\n",
    "                recJsonRDD = executeImplicitPlaylistAlgo(playlists, test, conf)\n",
    "                try:\n",
    "                    saveRecommendations(conf, recJsonRDD, overwrite=True)\n",
    "                    try:\n",
    "                        computeMetrics(conf)\n",
    "                    except:\n",
    "                        print 'Error in computing metrics'\n",
    "                except:\n",
    "                    print 'Error in saving recommndations'\n",
    "                    try:\n",
    "                        computeMetrics(conf)\n",
    "                    except:\n",
    "                        print 'Error in computing metrics'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
